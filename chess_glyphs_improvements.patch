From c6c7505b441038a2a9ba1788b951132f6a5e0a73 Mon Sep 17 00:00:00 2001
From: patchbot <patchbot@example.com>
Date: Thu, 14 Aug 2025 14:30:10 +0000
Subject: [PATCH] Debug endpoints (/compare_png, /health), rb flag; training
 (AMP, early stopping, IoU); lichess ingester; UI rule-based toggle.

---
 data/ingest_lichess_pgn.py | 57 ++++++++++++++++++++++++++++++++
 server.py                  | 40 +++++++++++++++++++++--
 train.py                   | 67 +++++++++++++++++++++++---------------
 ui/app.js                  |  3 +-
 utils/metrics.py           | 17 ++++++++++
 5 files changed, 155 insertions(+), 29 deletions(-)
 create mode 100644 data/ingest_lichess_pgn.py
 create mode 100644 utils/metrics.py

diff --git a/data/ingest_lichess_pgn.py b/data/ingest_lichess_pgn.py
new file mode 100644
index 0000000..01ade88
--- /dev/null
+++ b/data/ingest_lichess_pgn.py
@@ -0,0 +1,57 @@
+"""
+Lichess PGN ingestion (openings-focused).
+
+Usage:
+  python -m data.ingest_lichess_pgn --pgn lichess.pgn --out data/positions_openings.jsonl --max-games 20000 --ply-max 20 --bucket "1600-1999"
+"""
+import argparse, json, chess.pgn
+from collections import defaultdict
+
+def rating_bucket(white_elo, black_elo):
+    try:
+        w = int(white_elo); b = int(black_elo)
+    except:
+        return "all"
+    mean = (w+b)//2
+    if mean < 1200: return "U1200"
+    if mean < 1600: return "1200-1599"
+    if mean < 2000: return "1600-1999"
+    if mean < 2300: return "2000-2299"
+    return "2300+"
+
+def main():
+    ap = argparse.ArgumentParser()
+    ap.add_argument("--pgn", required=True)
+    ap.add_argument("--out", required=True)
+    ap.add_argument("--max-games", type=int, default=20000)
+    ap.add_argument("--ply-max", type=int, default=20, help="only positions up to this ply")
+    ap.add_argument("--bucket", type=str, default=None, help="filter by rating bucket")
+    args = ap.parse_args()
+
+    seen = set()
+    total = 0
+    with open(args.out, "w", encoding="utf-8") as out:
+        with open(args.pgn, "r", encoding="utf-8", errors="ignore") as f:
+            for i in range(args.max_games):
+                game = chess.pgn.read_game(f)
+                if game is None: break
+                welo = game.headers.get("WhiteElo", "0")
+                belo = game.headers.get("BlackElo", "0")
+                buck = rating_bucket(welo, belo)
+                if args.bucket and buck != args.bucket:
+                    continue
+                board = game.board()
+                ply = 0
+                for mv in game.mainline_moves():
+                    if ply > args.ply_max: break
+                    fen = board.fen()
+                    if fen not in seen:
+                        out.write(json.dumps({"fen": fen, "bucket": buck, "ply": ply}) + "\n")
+                        seen.add(fen)
+                        total += 1
+                    board.push(mv)
+                    ply += 1
+    print(f"Wrote {total} unique positions to {args.out}")
+
+if __name__ == "__main__":
+    main()
diff --git a/server.py b/server.py
index f97831b..80f0b11 100644
--- a/server.py
+++ b/server.py
@@ -3,10 +3,13 @@ from flask import Flask, request, jsonify, send_from_directory
 import chess
 import torch
 import numpy as np
+from io import BytesIO
+from PIL import Image
 
 from glyphs.labelers import board_to_planes, label_glyphs
 from model.drawer import DrawerNet
 from glyphs.spec import GLYPH_CHANNELS
+from render.renderer import render_glyphs
 
 app = Flask(__name__, static_folder="ui", static_url_path="/ui")
 
@@ -44,6 +47,7 @@ def index():
 @app.route("/predict", methods=["GET"])
 def predict():
     fen = request.args.get("fen", None)
+    rb = request.args.get("rb", None)  # force rule-based
     if not fen:
         return jsonify({"error": "Missing fen param"}), 400
     try:
@@ -51,7 +55,7 @@ def predict():
     except Exception as e:
         return jsonify({"error": f"Invalid FEN: {e}"}), 400
 
-    if MODEL is not None:
+    if (MODEL is not None) and (not rb):
         x = torch.from_numpy(board_to_planes(board)).unsqueeze(0).to(DEVICE)
         with torch.no_grad():
             pred = torch.sigmoid(MODEL(x)).cpu().numpy()[0]  # [10,8,8]
@@ -94,10 +98,42 @@ def move():
     out = {name: glyphs[idx].tolist() for idx, name in enumerate(GLYPH_CHANNELS)}
     return jsonify({"fen": new_fen, "glyphs": out})
 
+@app.route("/compare_png", methods=["GET"])
+def compare_png():
+    fen = request.args.get("fen", None)
+    if not fen:
+        return "Missing fen", 400
+    try:
+        board = chess.Board(fen)
+    except Exception as e:
+        return f"Invalid FEN: {e}", 400
+
+    gt = label_glyphs(board)
+
+    if MODEL is not None:
+        x = torch.from_numpy(board_to_planes(board)).unsqueeze(0).to(DEVICE)
+        with torch.no_grad():
+            pred = torch.sigmoid(MODEL(x)).cpu().numpy()[0]
+    else:
+        pred = gt
+
+    img_gt = render_glyphs(board, gt, size=480)
+    img_pr = render_glyphs(board, pred, size=480)
+
+    w = img_gt.width + img_pr.width
+    h = max(img_gt.height, img_pr.height)
+    canvas = Image.new("RGBA", (w, h), (20,20,25,255))
+    canvas.paste(img_gt, (0,0))
+    canvas.paste(img_pr, (img_gt.width, 0))
+
+    bio = BytesIO()
+    canvas.save(bio, format="PNG")
+    bio.seek(0)
+    return app.response_class(bio.getvalue(), mimetype="image/png")
+
 if __name__ == "__main__":
     host = os.environ.get("HOST", "127.0.0.1")
     port = int(os.environ.get("PORT", "8000"))
     print("[server] Starting at http://%s:%d" % (host, port))
-    # Print routes so you can confirm /move is registered
     print("[server] Routes:", [str(r) for r in app.url_map.iter_rules()])
     app.run(host=host, port=port, debug=True)
diff --git a/train.py b/train.py
index 554f4c0..c4e14a6 100644
--- a/train.py
+++ b/train.py
@@ -1,21 +1,21 @@
-import argparse, os, torch, numpy as np
+import argparse, os, torch, numpy as np, time
 import torch.nn.functional as F
 from torch.utils.data import DataLoader
 from tqdm import tqdm
 from data.dataset import PositionDataset
 from model.drawer import DrawerNet
+from utils.metrics import bce_with_logits, per_channel_iou_from_logits
 
-def bce_loss(pred_logits, target):
-    # pred_logits: [B,10,8,8], target: [B,10,8,8]
-    return F.binary_cross_entropy_with_logits(pred_logits, target)
-
-def l1_sparse_loss(pred_logits, weight=1e-3):
-    # encourage sparse glyphs post-sigmoid
+def l1_sparse_loss(pred_logits, weight=5e-4):
     p = torch.sigmoid(pred_logits)
     return weight * p.mean()
 
 def train(args):
     os.makedirs(os.path.dirname(args.out), exist_ok=True)
+    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    print(f"[train] device: {device} | cuda: {torch.cuda.is_available()}")
+    if torch.cuda.is_available():
+        print(f"[train] GPU name: {torch.cuda.get_device_name(0)}")
 
     ds = PositionDataset(args.positions)
     n_total = len(ds.items)
@@ -26,55 +26,70 @@ def train(args):
     ds.set_split("val")
     val_loader = DataLoader(ds, batch_size=args.batch_size, shuffle=False, num_workers=0)
 
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
     net = DrawerNet(width=args.width, depth=args.depth).to(device)
     opt = torch.optim.Adam(net.parameters(), lr=args.lr)
+    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == "cuda"))
+
+    best_val = float("inf")
+    best_epoch = 0
 
-    best_val = 1e9
     for epoch in range(1, args.epochs+1):
+        # Train
         ds.set_split("train")
         net.train()
         pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{args.epochs} [train]")
         total = 0.0
         for x, y in pbar:
-            x = x.to(device)
-            y = y.to(device)
-            logits = net(x)
-            loss = bce_loss(logits, y) + l1_sparse_loss(logits, weight=args.l1)
-            opt.zero_grad()
-            loss.backward()
-            opt.step()
+            x = x.to(device); y = y.to(device)
+            opt.zero_grad(set_to_none=True)
+            with torch.cuda.amp.autocast(enabled=(device.type=="cuda")):
+                logits = net(x)
+                loss = bce_with_logits(logits, y) + l1_sparse_loss(logits, weight=args.l1)
+            scaler.scale(loss).backward()
+            scaler.step(opt)
+            scaler.update()
             total += loss.item() * x.size(0)
             pbar.set_postfix(loss=f"{loss.item():.4f}")
-        train_loss = total / n_train
+        train_loss = total / max(1,n_train)
 
-        # validation
+        # Val
         ds.set_split("val")
         net.eval()
         total = 0.0
+        iou_sum = None
         with torch.no_grad():
             for x, y in val_loader:
                 x = x.to(device); y = y.to(device)
                 logits = net(x)
-                loss = bce_loss(logits, y) + l1_sparse_loss(logits, weight=args.l1)
+                loss = bce_with_logits(logits, y) + l1_sparse_loss(logits, weight=args.l1)
                 total += loss.item() * x.size(0)
-        val_loss = total / n_val if n_val>0 else train_loss
-        print(f"Epoch {epoch}: train {train_loss:.4f} | val {val_loss:.4f}")
+                iou = per_channel_iou_from_logits(logits, y)  # (C,)
+                iou_sum = iou if iou_sum is None else (iou_sum + iou)
+        val_loss = total / max(1,n_val) if n_val>0 else train_loss
+        iou_mean = (iou_sum / max(1, len(val_loader))).mean().item() if iou_sum is not None else 0.0
+        print(f"Epoch {epoch}: train {train_loss:.4f} | val {val_loss:.4f} | IoU(avg) {iou_mean:.3f}")
 
-        if val_loss < best_val:
+        improved = val_loss < best_val - 1e-5
+        if improved:
             best_val = val_loss
+            best_epoch = epoch
+            os.makedirs(os.path.dirname(args.out), exist_ok=True)
             torch.save({"state_dict": net.state_dict(), "args": vars(args)}, args.out)
             print(f"Saved best checkpoint to {args.out}")
+        elif epoch - best_epoch >= args.patience:
+            print(f"[early stopping] no improvement in {args.patience} epochs (best @ {best_epoch})")
+            break
 
 if __name__ == "__main__":
     ap = argparse.ArgumentParser()
     ap.add_argument("--positions", type=str, required=True)
-    ap.add_argument("--epochs", type=int, default=3)
-    ap.add_argument("--batch-size", type=int, default=64)
+    ap.add_argument("--epochs", type=int, default=30)
+    ap.add_argument("--batch-size", type=int, default=128)
     ap.add_argument("--lr", type=float, default=3e-4)
     ap.add_argument("--width", type=int, default=64)
-    ap.add_argument("--depth", type=int, default=4)
-    ap.add_argument("--l1", type=float, default=1e-3, help="L1 sparsity weight")
+    ap.add_argument("--depth", type=int, default=6)
+    ap.add_argument("--l1", type=float, default=5e-4, help="L1 sparsity weight")
+    ap.add_argument("--patience", type=int, default=5, help="early stopping patience (epochs)")
     ap.add_argument("--out", type=str, default="checkpoints/drawer.pt")
     args = ap.parse_args()
     train(args)
diff --git a/ui/app.js b/ui/app.js
index 17eb708..02b2b4e 100644
--- a/ui/app.js
+++ b/ui/app.js
@@ -17,6 +17,7 @@ const chkAttacks = document.getElementById('chk-attacks');
 const chkHanging = document.getElementById('chk-hanging');
 const chkPins = document.getElementById('chk-pins');
 const chkKing = document.getElementById('chk-king');
+const chkRulebased = (()=>{const l=document.createElement('label'); l.innerHTML='<input type="checkbox" id="chk-rule"> Rule-based only'; document.querySelector('.controls .row.small').appendChild(l); return document.getElementById('chk-rule');})();
 
 // Position state
 let fen = "startpos";
@@ -136,7 +137,7 @@ function drawOverlay(glyphs){
 }
 
 async function refreshGlyphs(){
-  const res = await fetch(`/predict?fen=${encodeURIComponent(fen)}`);
+  const res = await fetch(`/predict?fen=${encodeURIComponent(fen)}${(typeof chkRulebased!=='undefined' && chkRulebased.checked)?'&rb=1':''}`);
   const data = await res.json();
   if (data.glyphs){
     drawOverlay(data.glyphs);
diff --git a/utils/metrics.py b/utils/metrics.py
new file mode 100644
index 0000000..a054eaf
--- /dev/null
+++ b/utils/metrics.py
@@ -0,0 +1,17 @@
+import torch
+import torch.nn.functional as F
+
+def bce_with_logits(pred, target):
+    return F.binary_cross_entropy_with_logits(pred, target)
+
+@torch.no_grad()
+def per_channel_iou_from_logits(logits, target, thresh=0.5, eps=1e-6):
+    """
+    logits: [B,C,H,W], target: [B,C,H,W] in {0,1}
+    returns IoU per channel (C,)
+    """
+    pred = (torch.sigmoid(logits) > thresh).float()
+    inter = (pred * target).sum(dim=(0,2,3))
+    union = ((pred + target) > 0).float().sum(dim=(0,2,3))
+    iou = (inter + eps) / (union + eps)
+    return iou
-- 
2.39.2

